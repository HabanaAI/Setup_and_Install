# Copyright (c) 2022 HabanaLabs, Ltd.
#
# SPDX-License-Identifier: Apache-2.0
#
# HabanaLabs Dockerfile Tensorflow installer layer for RHEL 8.3

ARG BASE_NAME
ARG VERSION
ARG REVISION
FROM ${BASE_NAME}:${VERSION}-${REVISION}
ARG VERSION
ARG REVISION
ARG TF_VERSION
ARG ARTIFACTORY_URL
ARG HABANA_PIP_VERSION="21.1.1"

ENV TF_MODULES_RELEASE_BUILD=/usr/lib/habanalabs/
ENV PYTHONPATH=/root:/usr/lib/habanalabs/

# Install unzip to extract pre-trained weights for BERT demo
RUN dnf install -y libarchive unzip \
        git \
        bc \
        python38-devel \
        protobuf-devel && \
    dnf clean all && rm -rf /var/cache/dnf

COPY requirements-tensorflow-cpu-"$TF_VERSION".txt requirements-tensorflow-cpu-"$TF_VERSION".txt

RUN python3 -m pip install pip=="${HABANA_PIP_VERSION}" && \
    pip3 install setuptools==60.5.0

RUN pip3 install tensorflow-cpu==${TF_VERSION} \
        tensorflow-model-optimization==0.7.0 && \
    pip3 install -r requirements-tensorflow-cpu-"$TF_VERSION".txt && \
    rm requirements-tensorflow-cpu-"$TF_VERSION".txt

# For AML/CentOS/RHEL OS'es TFIO_DATAPATH have to be specified to import tensorflow_io lib correctly
ENV TFIO_DATAPATH=/usr/local/lib64/python3.8/site-packages/

# For AML/CentOS/RHEL ca-cert file is expected exactly under /etc/ssl/certs/ca-certificates.crt
# otherwise curl will fail during access to S3 AWS storage
RUN ln -s /etc/ssl/certs/ca-bundle.crt /etc/ssl/certs/ca-certificates.crt

RUN python3 -m pip install habana-tensorflow=="${VERSION}"."${REVISION}" && \
    python3 -m pip install habana-horovod=="${VERSION}"."${REVISION}"

RUN /usr/bin/ssh-keygen -A && \
    echo "source /etc/profile.d/habanalabs.sh" >> ~/.bashrc && \
    echo "/usr/sbin/sshd -p 3022" >> ~/.bashrc && \
    dnf clean all && rm -rf /var/cache/dnf && rm -rf /tmp/*